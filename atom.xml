<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Delia&#39;s Blog</title>
  
  <subtitle>纠结的快乐废柴</subtitle>
  <link href="http://delia.github.io/child/atom.xml" rel="self"/>
  
  <link href="http://delia.github.io/child/"/>
  <updated>2020-12-13T05:12:29.000Z</updated>
  <id>http://delia.github.io/child/</id>
  
  <author>
    <name>丁大锤</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FaRM</title>
    <link href="http://delia.github.io/child/2020/12/13/faRM/"/>
    <id>http://delia.github.io/child/2020/12/13/faRM/</id>
    <published>2020-12-13T05:12:08.000Z</published>
    <updated>2020-12-13T05:12:29.000Z</updated>
    
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式计算" scheme="http://delia.github.io/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>消息队列原理与实践</title>
    <link href="http://delia.github.io/child/2020/12/13/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://delia.github.io/child/2020/12/13/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</id>
    <published>2020-12-13T04:50:20.000Z</published>
    <updated>2020-12-14T02:46:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>传统通信方式</p><ul><li>进程间通信<br>问题: 不同语言间无法通信、多进程同时通信时顺序问题</li><li>机器间通信<br>可以通过网络、RPC等进行通信<a id="more"></a></li></ul><p>问题:</p><ol><li>如果集群需要扩容或者其他IP变更、接口变更、维护代驾高；  </li><li>容错处理：宕机、网络问题等</li></ol><h1 id="消息队列介绍"><a href="#消息队列介绍" class="headerlink" title="消息队列介绍"></a>消息队列介绍</h1><ul><li>消息<br>自定义结构， JSON、二进制等;<br>一般使用时，会自定义header、type、body等  </li><li>队列<br>FIFO<br>能cache消息</li></ul><h1 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h1><h2 id="P2P-JMS"><a href="#P2P-JMS" class="headerlink" title="P2P(JMS)"></a>P2P(JMS)</h2><p>1v1的消费者和生产者<br>消费者接收消息之后需要像队列应答成功</p><ol start="2"><li>ACK<br>什么时候需要必达？<br>确认消息有没有丢失  </li></ol><p>生产者和队列之间的ack？<br>分布式带来ack的复杂性</p><p>消费者和队列之间的ack？  </p><ul><li>至少一次 用来容错，如果因为网络等原因导致ack失败，就会重试</li><li>最多一次</li><li>有且只有一次  分布式场景较难，很难保证原子性</li></ul><h2 id="Pub-sub-JMS"><a href="#Pub-sub-JMS" class="headerlink" title="Pub/sub (JMS)"></a>Pub/sub (JMS)</h2><ul><li>每个消息可以有多个消费者</li><li>发布者和订阅者之间有时间上的依赖性，针对某个topic的订阅者，必须创建一个订阅者之后，才能消费发布者的信息</li><li>订阅者必须保持运行的状态</li></ul><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>假设有一个乘客发单 ——&gt; 订单 ———&gt; 司机接单的系统</p><ol><li>订单需要确认有没有被司机接到： 如果要ack怎么办</li><li>司机接单系统挂了 乘客就不能发单了吗？<br>消息队列有一定的缓存功能<br>内存和</li><li>如果要trace1天前的订单， 可以消费以前的消息吗？</li><li>一对多的时候， 一条消息消费了， 其它消费者怎么办？</li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;传统通信方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;进程间通信&lt;br&gt;问题: 不同语言间无法通信、多进程同时通信时顺序问题&lt;/li&gt;
&lt;li&gt;机器间通信&lt;br&gt;可以通过网络、RPC等进行通信</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="消息队列" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="http://delia.github.io/child/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Raft</title>
    <link href="http://delia.github.io/child/2020/12/13/Raft/"/>
    <id>http://delia.github.io/child/2020/12/13/Raft/</id>
    <published>2020-12-13T04:43:18.000Z</published>
    <updated>2020-12-13T04:50:20.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h1><p>论文:《Resilient Distributed Datasets: A Fault-Tolerant Abstraction forIn-Memory Cluster Computing》<br>关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance </p><a id="more"></a>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;关键词&quot;&gt;&lt;a href=&quot;#关键词&quot; class=&quot;headerlink&quot; title=&quot;关键词&quot;&gt;&lt;/a&gt;关键词&lt;/h1&gt;&lt;p&gt;论文:《Resilient Distributed Datasets: A Fault-Tolerant Abstraction forIn-Memory Cluster Computing》&lt;br&gt;关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance &lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式计算" scheme="http://delia.github.io/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Spark</title>
    <link href="http://delia.github.io/child/2020/12/13/spark/"/>
    <id>http://delia.github.io/child/2020/12/13/spark/</id>
    <published>2020-12-13T04:38:44.000Z</published>
    <updated>2020-12-13T04:50:20.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h1><p>论文:《Resilient Distributed Datasets: A Fault-Tolerant Abstraction forIn-Memory Cluster Computing》<br>关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance </p><a id="more"></a>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;关键词&quot;&gt;&lt;a href=&quot;#关键词&quot; class=&quot;headerlink&quot; title=&quot;关键词&quot;&gt;&lt;/a&gt;关键词&lt;/h1&gt;&lt;p&gt;论文:《Resilient Distributed Datasets: A Fault-Tolerant Abstraction forIn-Memory Cluster Computing》&lt;br&gt;关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance &lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式计算" scheme="http://delia.github.io/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce</title>
    <link href="http://delia.github.io/child/2020/12/13/MapReduce/"/>
    <id>http://delia.github.io/child/2020/12/13/MapReduce/</id>
    <published>2020-12-13T04:34:06.000Z</published>
    <updated>2020-12-13T15:10:32.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h1><p>论文:《MapReduce: Simplified Data Processing on Large Clusters》<br>关键词：1、parallelization 2、fault-tolerance 3、data distribution  4、load balancing</p><a id="more"></a><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p><img src="https://images0.cnblogs.com/blog/579512/201311/16105654-dd109e49f8b24b009add7af8608da1bd.png" alt="架构"></p><ol><li>fork</li><li>assign map &amp; reduce</li><li>read</li><li>local write</li><li>remote read</li><li>write</li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;关键词&quot;&gt;&lt;a href=&quot;#关键词&quot; class=&quot;headerlink&quot; title=&quot;关键词&quot;&gt;&lt;/a&gt;关键词&lt;/h1&gt;&lt;p&gt;论文:《MapReduce: Simplified Data Processing on Large Clusters》&lt;br&gt;关键词：1、parallelization 2、fault-tolerance 3、data distribution  4、load balancing&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式计算" scheme="http://delia.github.io/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>airflow部署</title>
    <link href="http://delia.github.io/child/2020/12/12/airflow%E9%83%A8%E7%BD%B2/"/>
    <id>http://delia.github.io/child/2020/12/12/airflow%E9%83%A8%E7%BD%B2/</id>
    <published>2020-12-12T10:55:24.000Z</published>
    <updated>2020-12-12T11:02:55.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="搭建airflow"><a href="#搭建airflow" class="headerlink" title="搭建airflow"></a>搭建airflow</h1><p><a href="https://airflow.apache.org/docs/stable/installation.html">官方文档</a></p><a id="more"></a><h2 id="准备数据库"><a href="#准备数据库" class="headerlink" title="准备数据库"></a>准备数据库</h2><p>CREATE DATABASE airflow_hmc;<br>alter user  XXX with password ‘XXXX’;<br>GRANT ALL PRIVILEGES ON DATABASE airflow TO airflow;  </p><h2 id="设置-airflow-项目路径"><a href="#设置-airflow-项目路径" class="headerlink" title="设置 airflow 项目路径"></a>设置 airflow 项目路径</h2><p>vim ~/.bash_profile<br>export AIRFLOW_HOME=/home/xiaoju/airflow</p><h2 id="安装airflow"><a href="#安装airflow" class="headerlink" title="安装airflow"></a>安装airflow</h2><p>pip install apache-airflow<br>服务器安装巨慢  可以用公司的源<br>pip install xxx –trusted-host </p><h2 id="配置自己的数据库"><a href="#配置自己的数据库" class="headerlink" title="配置自己的数据库"></a>配置自己的数据库</h2><p>更改~/airflow/airflow.cfg<br>executor = LocalExecutor<br>sql_alchemy_conn = postgresql+psycopg2://user:pass@hostadress:port/database<br>最后再重新初始化db</p><p>airflow initdb<br>airflow resetdb</p><p>然后自动生成数据库结构， 包括job信息、task信息、dag信息。</p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>airflow webserver -p 8080<br>守护进程启动加 -D</p><h2 id="开始demo"><a href="#开始demo" class="headerlink" title="开始demo"></a>开始demo</h2><p><a href="https://blog.csdn.net/SunnyYoona/article/details/76615699">参考</a></p><p>编写hello word<br>测试代码正确性: python ~/opt/airflow/dags/hello_world.py<br>展示task任务： airflow list_tasks example_hello_world_dag<br>测试单task正确性 ：airflow test example_hello_world_dag date_task 20170803<br>运行DAG： airflow scheduler就可以在界面上看到自己的任务了</p><h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><p>删除默认示例<br>Edit airflow.cfg and set load_examples = False<br>airflow resetdb<br><a href="https://cloud.tencent.com/developer/article/1531063">修改时区</a></p><h1 id="搭建分布式"><a href="#搭建分布式" class="headerlink" title="搭建分布式"></a>搭建分布式</h1><h2 id="搭建redis"><a href="#搭建redis" class="headerlink" title="搭建redis"></a>搭建redis</h2><ul><li>下载redis包 wget <a href="http://download.redis.io/releases/redis-3.0.7.tar.gz">http://download.redis.io/releases/redis-3.0.7.tar.gz</a> 放在/usr/local/目录下</li><li>编译  make   make install PREFIX=/usr/local/redis</li><li>启动 /usr/local/redis/bin目录下   ./redis-server &amp;</li><li>redis启动 /usr/local/redis/bin$ ./redis-cli -p  6379<h2 id="安装celery"><a href="#安装celery" class="headerlink" title="安装celery"></a>安装celery</h2>pip install celery</li></ul><h2 id="配置redis"><a href="#配置redis" class="headerlink" title="配置redis"></a>配置redis</h2><p>修改broker_url, result_backend<br>配置主节点位置 cluster_addres</p><h2 id="worker-节点部署"><a href="#worker-节点部署" class="headerlink" title="worker 节点部署"></a>worker 节点部署</h2><p>部署了一主两从，在master上启动webserver 和 scheduler<br>在slave上启动 worker</p><h2 id="文件同步"><a href="#文件同步" class="headerlink" title="文件同步"></a>文件同步</h2><p>airflow只提供命令同步， 不负责文件同步, 使用rsync进行多节点文件同步</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;搭建airflow&quot;&gt;&lt;a href=&quot;#搭建airflow&quot; class=&quot;headerlink&quot; title=&quot;搭建airflow&quot;&gt;&lt;/a&gt;搭建airflow&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://airflow.apache.org/docs/stable/installation.html&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="环境部署" scheme="http://delia.github.io/child/categories/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"/>
    
    <category term="airflow" scheme="http://delia.github.io/child/categories/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/airflow/"/>
    
    
    <category term="环境部署" scheme="http://delia.github.io/child/tags/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>airflow简介</title>
    <link href="http://delia.github.io/child/2020/12/12/airflow%E7%AE%80%E4%BB%8B/"/>
    <id>http://delia.github.io/child/2020/12/12/airflow%E7%AE%80%E4%BB%8B/</id>
    <published>2020-12-12T09:14:07.000Z</published>
    <updated>2020-12-13T02:55:12.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="airflow简介"><a href="#airflow简介" class="headerlink" title="airflow简介"></a>airflow简介</h1><p><a href="https://airflow.apache.org/docs/stable/">官方文档</a></p><a id="more"></a><h2 id="1-1-干嘛的"><a href="#1-1-干嘛的" class="headerlink" title="1.1 干嘛的"></a>1.1 干嘛的</h2><p>分布式任务调度系统</p><ul><li>组织任务编排</li><li>管理任务依赖</li><li>调度任务工作流</li><li>监视任务执行状态</li></ul><p><strong>关键字</strong></p><ul><li>动态性  </li><li>可扩展性   可以自动以操作器、执行器等</li><li>优雅性  使用jinja模板引擎使 脚本参数化</li><li>可伸缩性  模块化 使用消息队列来协调worker</li></ul><h2 id="1-2-整体架构"><a href="#1-2-整体架构" class="headerlink" title="1.2 整体架构"></a>1.2 整体架构</h2><p><strong>1.2.1 整体介绍</strong><br>在一个可扩展的生产环境中，Airflow通常含有以下组件：</p><table><thead><tr><th align="left">组件</th><th align="center">名称</th><th align="center">职责</th><th align="left">职责</th></tr></thead><tbody><tr><td align="left">一个元数据库</td><td align="center">Database</td><td align="center">存储任务、DAGs 变量 连接等信息</td><td align="left">MySQL 或 Postgres</td></tr><tr><td align="left">一组Airflow工作节点</td><td align="center">Workers</td><td align="center">接收任务并执行任务</td><td align="left"></td></tr><tr><td align="left">一个Airflow调度器</td><td align="center">Scheduler</td><td align="center">周期性地轮询任务的调度计划，以确定是否触发任务执行,根据dags生成任务，并提交到消息中间件队列中</td><td align="left"></td></tr><tr><td align="left">一个调节器</td><td align="center">Celery</td><td align="center">队列机制。Celery由Broker（代理）和Result backend（结果后端）两个组件组成。Broker负责存储执行的命令。Result backend存储完成执行命令的状态信息。</td><td align="left">Redis或RabbitMQ</td></tr><tr><td align="left">一个Airflow Web服务器</td><td align="center">WebServer</td><td align="center">提供web端服务，以及会定时生成子进程去扫描对应的目录下的dags，并更新数据库</td><td align="left"></td></tr></tbody></table><p><img src="https://airflow.apache.org/docs/apache-airflow/stable/_images/graphviz-91fd3ca4f3dc01a69b3f84fbcd6b5c7975945ba4.png" alt="架构图" title="架构图"></p><p>各种组件之间的通信</p><ol><li>Web server –&gt; Workers ： 获取任务执行日志。</li><li>Web server –&gt; DAG files ： 展示DAG结构。</li><li>Web server –&gt; Database ：获取任务状态。</li><li>Workers –&gt; DAG files ：展示DAG结构和执行任务。</li><li>Workers –&gt; Database ： 获取和存储连接配置信息、变量XCOM。</li><li>Workers –&gt; Celery’s result backend ： 存储任务执行信息。</li><li>Workers –&gt; Celery’s broker ：存储执行的命令。</li><li>Scheduler –&gt; Database ： 存储DAG运行信息和相关的任务。</li><li>Scheduler –&gt; DAG files ： 展示DAG的结构和执行任务。</li><li>Scheduler –&gt; Celery’s result backend ： 获取已经执行完的任务信息。</li><li>Scheduler –&gt; Celery’s broker ： 把执行的命令发送给Celery’s broker。</li></ol><p><strong>1.2.2  单机模式和分布式模式的区别</strong><br>Worker的具体实现由配置文件中的executor来指定，airflow支持多种Executor:</p><ul><li>SequentialExecutor: 单进程顺序执行，一般只用来测试</li><li>LocalExecutor: 本地多进程执行</li><li>CeleryExecutor: 使用Celery进行分布式任务调度</li><li>DaskExecutor：使用Dask进行分布式任务调度</li><li>KubernetesExecutor: 1.10.0新增, 创建临时POD执行每次任务<br>其中常用的是CeleryExecutor 和 KubernetesExecutor。 这里介绍下LocalExecutor 和 CeleryExecutor 分别代表单机和分布式模式。</li></ul><p>分布式模式<br><img src="https://img-blog.csdnimg.cn/20190916182738947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTY1ODQzNA==,size_16,color_FFFFFF,t_70" alt="单机模式"></p><ol><li>Schedual读取配置文件 将Job信息发给RabbitMQ， 并在数据库里注册Job信息</li><li>RabbitMQ里有很多channel， schedual根据Job信息 发到对应的channel</li><li>Executor会被配置为 Celery Executor（在 airflow.cfg 中配置），并且指向 RabbitMQ Broker， 消费RabbitMQ对应的channel。  </li><li>Worker 被安装在不同的节点上，它们从 RabbitMQ Broker 中读取任务，并执行，最终将结果写入数据库。</li><li>Web读取MySQL里面的Job信息，展示Job的执行结果</li></ol><p>单机模式<br><img src="https://img-blog.csdnimg.cn/2019091618314065.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTY1ODQzNA==,size_16,color_FFFFFF,t_70" alt="单机模式"></p><h2 id="1-3-核心概念"><a href="#1-3-核心概念" class="headerlink" title="1.3  核心概念"></a>1.3  核心概念</h2><p><strong>1.3.1 DAG图</strong> </p><p>即有向无环图(Directed Acyclic Graph)，将所有需要运行的tasks按照依赖关系组织起来, 描述的是一个工作流的过程。<br>DAG 不关心里面的任务做了什么事情，而是关心  </p><ul><li>任务在特定的时间开始</li><li>若干任务以正确的顺序进行</li><li>对未期望的情况有正确的处理</li></ul><p><strong>1.3.2 Operators</strong><br>DAG定义了一个工作流，operators定义了工作流中的每一task具体做什么事情。一个operator定义工作流中一个task，每个operator是独立执行的，不需要和其他的operator共享信息。它们可以分别在不同的机器上执行。<br>如果你真的需要在两个operator之间共享信息，可以使用airflow提供的Xcom功能。  </p><p><strong>1.3.3 Tasks</strong><br>Task为DAG中具体的作业任务，依赖于DAG，也就是必须存在于某个DAG中。<br>Task在DAG中可以配置依赖关系（当然也可以配置跨DAG依赖，但是并不推荐。跨DAG依赖会导致DAG图的直观性降低，并给依赖管理带来麻烦）。</p><p><strong>1.3.4 Hooks</strong><br>建立一个与外部数据系统之间的连接，比如Mysql，HDFS，本地文件系统(文件系统也被认为是外部系统)等，通过拓展Hook能够接入任意的外部系统的接口进行连接，这样就解决的外部系统依赖问题。  </p><p>##1.3  优缺点<br><strong>优点</strong>  </p><ol><li>解决任务依赖问题，可以设定各种触发条件, 便于对任务进行状态管理</li><li>丰富的ui管理界面，任务的启停、日志管理、甘特图等 可以便捷的知道程序运行状态。  </li></ol><p><strong>缺点</strong>  </p><ol><li>分布式部署麻烦</li><li>task拆分得很细，这样的话，如果某个task失败，重跑的代价会比较低。但是，tasks太多时，airflow在调度tasks会很低效，airflow一直处于选择待执行的task的过程中，会长时间没有具体task在执行，从而整体执行效率大幅降低。  </li></ol><h2 id="1-4-竞品比较"><a href="#1-4-竞品比较" class="headerlink" title="1.4 竞品比较"></a>1.4 竞品比较</h2><p>Apache Airflow<br>LinkedIn Azkaban<br>Apache Oozie</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;airflow简介&quot;&gt;&lt;a href=&quot;#airflow简介&quot; class=&quot;headerlink&quot; title=&quot;airflow简介&quot;&gt;&lt;/a&gt;airflow简介&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://airflow.apache.org/docs/stable/&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="环境部署" scheme="http://delia.github.io/child/categories/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"/>
    
    <category term="airflow" scheme="http://delia.github.io/child/categories/%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/airflow/"/>
    
    
    <category term="分布式调度" scheme="http://delia.github.io/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>GFS</title>
    <link href="http://delia.github.io/child/2020/10/05/distributed-system-GFS/"/>
    <id>http://delia.github.io/child/2020/10/05/distributed-system-GFS/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-12-13T04:50:20.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h1><p>论文:《The Google File System》<br>关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance </p><a id="more"></a><h1 id="分布式存储的背景"><a href="#分布式存储的背景" class="headerlink" title="分布式存储的背景"></a>分布式存储的背景</h1><ol><li>系统由很多廉价的组件构成，并且组件会经常失败， 因此要注意持续的监控 、错误侦测、灾难冗余、 自动恢复</li><li>系统存储量大，支持GB级的大文件，因此需要考虑IO操作和block设计的大小</li><li>既要支持大规模的流式读取，也要支持小规模的随机读取。 为了提高性能，可以把小规模随机读操作进行合并，变成批量顺序读</li><li>支持大规模顺序追加写，对于小规模的随机写，性能不咋滴</li><li>必须高效的支持多个用户同时写一个文件，通过协同设计来满足灵活性，减轻了GFS一致性的要求； 引进了原子性的追加写</li><li>高性能的稳定网络带宽远比低延迟重要</li></ol><h1 id="GFS架构"><a href="#GFS架构" class="headerlink" title="GFS架构"></a>GFS架构</h1><p>GFS: 一个GFS集群是由一个master、多个chunkservers构成，支持多个客服端访问。<br><img src="https://images2015.cnblogs.com/blog/715283/201609/715283-20160917222135977-1214346793.png" alt="架构"></p><h2 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h2><p>因为master节点只有一个，所以要减少它的读写，避免master成为瓶颈。因此客户端和Master节点的通信只获取元数据，所有的数据操作都是由客户端直接和Chunk服务器进行交互的<br>读流程：</p><ul><li>Step1 客户端根据文件名和字节偏移生成chunk index</li><li>Step2 客户端把chunk index 和 文件名 发送给master</li><li>Step3 master返回对应的chunk handle 和 副本的位置</li><li>Step4 客户端会以文件名和chunk index 来缓存信息 (chunk handle 和 副本)</li><li>Step5 客户端会向最近的一个副本请求数据</li></ul><h2 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h2><p>见5.1介绍</p><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="chunk-server"><a href="#chunk-server" class="headerlink" title="chunk server"></a>chunk server</h2><p>chunk size的大小直接影响系统的吞吐指标，chunk size越大越能利用磁盘的顺序读能力<br>一个chunk一般选用64MB（一般文件系统的块大小是4K），采用惰性空间分配防止内存碎片造成空间浪费？？？<br>优点：</p><ol><li>减少客服端和主节点的直接交互</li><li>通过tcp长连接来减少网络IO</li><li>减少了存储在主节点上的元数据</li></ol><p>缺点：</p><ol><li>当大量客户端访问相同文件，容易产生热点问题。但由于缓存和顺序读，不会是大问题</li><li>批处理队列系统里，还是会出现热点问题( 没看懂)，短期解决办法:多复制几份、错开程序的启动时间，长期解决办法：允许从其它客服端读取</li></ol><h2 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h2><p>master服务器存储3种类型的元数据：</p><ol><li>文件和块的命名空间, master内存 &amp;&amp; master磁盘 &amp;&amp; chunk 副本</li><li>文件到块的映射关系,  master内存 &amp;&amp;  master磁盘 &amp;&amp; chunk 副本</li><li>块副本的存储位置, master内存</li></ol><p><strong>内存数据结构</strong><br>master会定期扫描，用来实现chunk的垃圾回收、chunkserver失败时候的副本复制、以及平衡负载的chunk迁移？<br>一个问题是系统受限于master的内存，但不严重因为一个chunk的meta不足64kb，文件名也是以压缩的方式存储</p><p><strong>chunk位置</strong><br>为了解决master和chunkserver的同步问题，块位置缓存在内存不落盘，master启动时通过请求chunkserver获取位置信息，通过心跳来监控chunkserver的状态。</p><p><strong>操作日志</strong><br>为了确保操作日志的完整性，只有日志写到本地以及远程磁盘后，才会响应客户端操作。<br>1、master在操作日志量级达到一定程度时，会创建一个checkpoint文件，写入本地和远程的硬盘；<br>2、为了保证checkpoint文件不阻塞服务，会用独立线程切换到新的线程和checkpoint文件<br>3、master进行灾难恢复的时候，只需要恢复checkpoint和后面的日志文件。历史可以删除</p><h2 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h2><p><strong>一致性保障机制</strong><br>命名空间锁保证了原子性和正确性，操作日志保证了保证了顺序。<br>a) 对Chunk的所有副本的修改操作顺序一致<br>b) 通过chunk版本号来去掉过时的chunk<br>GFS通过master和chunkservers的定期handshake来检测破坏了的数据</p><h1 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h1><p>尽量在所有操作中减少master的交互</p><h2 id="租约"><a href="#租约" class="headerlink" title="租约"></a>租约</h2><p>租约的作用：分布式环境中维持缓存的一致性的一种协议。 最小化master节点负担。<br>租约本质上是一种有时间限制的锁：租约的持有者（chunk的某个副本）需要定期向Master申请续约。如果超过租约的期限，那么该租约会被强制收回并重新分配给其他副本。<br>GFS master颁发租约给某个chunk server，让它成为Primary 副本，当有多个client并发更新数据块时，由Primary副本确定并发更新该数据块的顺序。<br><img src="https://img-blog.csdn.net/20150318123959891" alt="租约"><br><strong>master和chunkserver的交互</strong></p><ol><li>客户端 向 master 请求某个chunk的 primary和sencondary的位置。 如果没有，则master授予令牌；</li><li>master应答, 客户端cache;</li><li>客户端把数据发给每一个chunkserver, chunkserver用LRU来cache；</li><li>所有chunkserver收到数据后，客户端发起写请求给master, master生成序列号；</li><li>primary发布写请求给secondary， 序列化执行写操作;</li><li>sencondary完成后, 告诉primary;</li><li>primary应答给客户端, 如果失败 重复3-7;</li></ol><h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><p>GFS 将写操作拆分为数据流（对应3）和控制流（对应4），数据流以 Pipline 的方式推送到所有副本。</p><ul><li>避免网络瓶颈以及高延时的连接，最小化同步数据的时间。  </li><li>基于TCP连接数据传输，来最大限度的减少延时<h2 id="原子记录操作"><a href="#原子记录操作" class="headerlink" title="原子记录操作"></a>原子记录操作</h2>追加只需指定要写入的数据，不需要提供偏移量（即要写入的位置）<br>GFS并不保证所有的副本都是byte级别相等的，保证至少一次成功<br>原子记录追加操作在避免了使用一个分布式锁带来的开销<br>当追加的chunk过大时，primary 会先将当前chunk填充满，然后同步给secondary同样操作，然后回复client要求其对下一个 chunk 重新执行追加操作</li></ul><h2 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h2><p>使用COW来实现快照</p><ul><li>废除所有的 lease，准备 snapshot（相当于暂停了所有写操作）；</li><li>不立即对指定Chunk拷贝，而只拷贝其元数据并对指定Chunk的引用计数增1</li><li>master 记录所有操作，并且将记录写入磁盘</li><li>master 将源文件和目录树的 metadata 进行复制，这样之前的记录就和当前的内存中所保存的状态对应起来了，新建的 snapshot 和源文件指向的会是同一个chunk</li></ul><h1 id="master-操作"><a href="#master-操作" class="headerlink" title="master 操作"></a>master 操作</h1><p>master执行所有的namespace的操作，还有chunk的位置选址、备份、完整性、平衡负载等任务。  </p><h2 id="命名空间管理"><a href="#命名空间管理" class="headerlink" title="命名空间管理"></a>命名空间管理</h2><p>由于master的操作比较重，会消耗很长的时间， 因此每一个namespace的节点都有都有一个相关的读写锁, 来保证操作的序列化。</p><ul><li>目录 –&gt; 读锁 –&gt; 防止被删除、改名、快照</li><li>文件 –&gt; 死锁 –&gt; 防止同名文件</li><li>读写锁 惰性分配 防止死锁<h2 id="副本选择"><a href="#副本选择" class="headerlink" title="副本选择"></a>副本选择</h2>副本选址有两个原则：</li><li>最大限度的保证数据的可靠和可用</li><li>最大限度的利用网络带宽<br>因此机器之间会复制，机架之间也会复制。<h2 id="重备份"><a href="#重备份" class="headerlink" title="重备份"></a>重备份</h2>有三个原因需要创建chunk的副本：chunk的创建，chunk的重新复制，chunk的重新均衡。  </li></ul><p><strong>选址考虑</strong></p><ul><li>选择磁盘使用率较低的</li><li>确保不会有太多”较新”的副本</li><li>跨越机架  </li></ul><p><strong>重备份顺序</strong></p><ul><li>与副本指定数量差距, 差距越大越先备份</li><li>越活跃的文件越先备份</li><li>阻塞用户的文件越先备份  </li></ul><p><strong>副本均衡</strong><br>master会定期进行均衡副本<br>低磁盘使用率的chunkserver上的chunk会优先选择</p><h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><ul><li>惰性回收<br>不会立即删除, 而是重命名成一个隐藏文件， 过了三天再删除</li><li>定期扫描<br>master会对chunk的namesapce进行定期扫描, 识别chunk孤点进行删除</li></ul><p><strong>优点</strong>  </p><ol><li>定期扫描，可以清除未知副本</li><li>是在master负载较轻的时候进行批处理的，比如对namespace的扫描、chunkserver的握手,</li><li>惰性回收可以避免误操作  </li></ol><p><strong>缺点</strong><br>存储资源紧张的话  影响负载均衡</p><h2 id="过期副本删除"><a href="#过期副本删除" class="headerlink" title="过期副本删除"></a>过期副本删除</h2><p>对于每一个chunk，master保持一个chunk的版本号码来区分最新的和过期的副本。<br>通过租约机制管理，primary通过命令管道发送给slave列表进行版本更新。<br>做版本号更新操作时将拒绝所有客户端对该块的写请求。<br>master通过正常的垃圾回收机制来删除过期的副本。</p><h1 id="容错和诊断"><a href="#容错和诊断" class="headerlink" title="容错和诊断"></a>容错和诊断</h1><h2 id="高可用性"><a href="#高可用性" class="headerlink" title="高可用性"></a>高可用性</h2><p>高可用性靠两点来保证: 备份与恢复<br><strong>1. 快速恢复</strong><br>reconnect and  restart<br><strong>2. chunk 备份</strong><br>不同机架上都有chunkserver的副本<br>master通过checksum来删除损坏的副本<br>后续可以讨论避免冗余存储<br><strong>3. master 备份</strong><br>master上的operation log和checkpoints是备份的<br>还存在一些 shadow master，在 master 宕机时能可以提供 read-only 服务，但要比 master 慢一些</p><h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p>每一个chunkserver上必须独立的效验自己的副本的完整性，通过checksum来检查<br>checksum存储在内存和磁盘上<br>读数据时会校验，写数据时更新checksum, chunkserver空闲时，会检查不常用的副本</p><ul><li>chunckserver返回数据前，会做checksum, 如果checksum不正确， 返回错误;</li><li>会从其它副本重新读取数据, 并且master安排其它副本克隆;</li><li>新副本克隆;</li><li>master指挥老server删除错误副本</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;关键词&quot;&gt;&lt;a href=&quot;#关键词&quot; class=&quot;headerlink&quot; title=&quot;关键词&quot;&gt;&lt;/a&gt;关键词&lt;/h1&gt;&lt;p&gt;论文:《The Google File System》&lt;br&gt;关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance &lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式存储" scheme="http://delia.github.io/child/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Primary-Backup Replication</title>
    <link href="http://delia.github.io/child/2020/10/05/distributed-system-primary-backup/"/>
    <id>http://delia.github.io/child/2020/10/05/distributed-system-primary-backup/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-10-05T05:18:24.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="论文导读"><a href="#论文导读" class="headerlink" title="论文导读"></a>论文导读</h1><p>论文：《actical System for Practical System forFault-Tolerant Virtual Machines<br>Fault-Tolerant Virtual Machines》</p><a id="more"></a><h1 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h1><p>1、state transfer (状态转移)<br>primary将整个ram都备份， 是转移内存<br>2、replicated state machine (备份状态机) 主<br>转移 operation。相同的状态、相同的启动就会有相同的输出。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;论文导读&quot;&gt;&lt;a href=&quot;#论文导读&quot; class=&quot;headerlink&quot; title=&quot;论文导读&quot;&gt;&lt;/a&gt;论文导读&lt;/h1&gt;&lt;p&gt;论文：《actical System for Practical System forFault-Tolerant Virtual Machines&lt;br&gt;Fault-Tolerant Virtual Machines》&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="主从备份" scheme="http://delia.github.io/child/tags/%E4%B8%BB%E4%BB%8E%E5%A4%87%E4%BB%BD/"/>
    
  </entry>
  
  <entry>
    <title>RPC and Threads</title>
    <link href="http://delia.github.io/child/2020/10/05/distributed-system-rpc/"/>
    <id>http://delia.github.io/child/2020/10/05/distributed-system-rpc/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-10-05T05:18:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>多线程协同 垃圾回收<br>1、多线程<br>goroutine</p><a id="more"></a><p>event-driven  和  多线程的区别？<br>当并发量过大时 线程切换的开销较大；一般高性能服务器都是 多线程和事件驱动结合来做</p><p>堆内存和栈内存 分配？<br>lua?</p><p>多线程的挑战：<br>1、共享内存<br>race、 condition 、 临界区问题锁<br>2、coordination<br>channel : 将数据从一个线程发送到另一个线程<br>condition variables ： 确定哪些线程运行<br>wait group:<br>3、死锁</p><p>推荐书籍：<br>1、《effective go》</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;多线程&quot;&gt;&lt;a href=&quot;#多线程&quot; class=&quot;headerlink&quot; title=&quot;多线程&quot;&gt;&lt;/a&gt;多线程&lt;/h2&gt;&lt;p&gt;多线程协同 垃圾回收&lt;br&gt;1、多线程&lt;br&gt;goroutine&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="rpc和线程" scheme="http://delia.github.io/child/tags/rpc%E5%92%8C%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Data Structures and Algorithms for Big Database 阅读笔记</title>
    <link href="http://delia.github.io/child/2020/10/05/paging/"/>
    <id>http://delia.github.io/child/2020/10/05/paging/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-10-05T09:20:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IO-and-cache-efficient-algorithm"><a href="#IO-and-cache-efficient-algorithm" class="headerlink" title="IO and cache-efficient algorithm"></a>IO and cache-efficient algorithm</h2><p>Disk Access Model：</p><p>cache-oblivious analysis：</p><a id="more"></a><h2 id="paging-algorithms"><a href="#paging-algorithms" class="headerlink" title="paging algorithms"></a>paging algorithms</h2><p>page fault,即中不存在所需数据而引入的错误，为了解决这个错误就需要从硬盘中读取数据到内存中。所以每个page fault都对应于一次硬盘读取，耗费大量时间。读到的数据需要覆盖内存中的某些现有数据，如何选择被替代的内存中的数据就是page replacement algorithm处理的问题。</p><p><strong>1.1 LRU: least recently used</strong></p><p>每次选择最不近使用的元素进行替换，算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。<br>首先将请求序列分为b个区块，每个区块内最多有k个元素，并且使得b尽可能小。<br>那么LRU对于每个区块最多遇到k个page fault，从而整体而言最多bk个page fault。而对于最优算法，至少遇到b个page fault，因为每次跳跃区块的时候都会遇到一个前一区块从未遇过的第k+1个元素，从而引入page fault。<br>所以LRU的competitive ratio ≤k，其中k为cache size。</p><p><strong>1.2 FIFO: first in,first out</strong></p><p><strong>1.3 LFU： least frequently used</strong></p><p><strong>1.4 random</strong></p><p><strong>1.5 LFD：longest forward distance</strong></p><p>也叫OPT optimal replacement algorithm<br>淘汰页面将是以后永不使用的，或许是在最长（未来）时间内不再被使用的页面<br>该算法保证了获得最低的缺页率，但是该算法无法实现。但是可以利用该算法去评价其他算法</p><p><strong>1.6  CPR：clock page Replacement Algorithm</strong></p><p>时钟替换算法</p><h2 id="参考blog"><a href="#参考blog" class="headerlink" title="参考blog"></a>参考blog</h2><p><a href="https://blog.csdn.net/silent56_th/article/details/78462738">https://blog.csdn.net/silent56_th/article/details/78462738</a><br><a href="https://www.cnblogs.com/CareySon/archive/2012/04/25/2470063.html">https://www.cnblogs.com/CareySon/archive/2012/04/25/2470063.html</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;IO-and-cache-efficient-algorithm&quot;&gt;&lt;a href=&quot;#IO-and-cache-efficient-algorithm&quot; class=&quot;headerlink&quot; title=&quot;IO and cache-efficient algorithm&quot;&gt;&lt;/a&gt;IO and cache-efficient algorithm&lt;/h2&gt;&lt;p&gt;Disk Access Model：&lt;/p&gt;
&lt;p&gt;cache-oblivious analysis：&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="LevelDB" scheme="http://delia.github.io/child/categories/%E5%AD%A6%E4%B9%A0/LevelDB/"/>
    
    
    <category term="paging algorithms" scheme="http://delia.github.io/child/tags/paging-algorithms/"/>
    
  </entry>
  
</feed>
