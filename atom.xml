<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Delia&#39;s Blog</title>
  
  <subtitle>纠结的快乐废柴</subtitle>
  <link href="http://delia.github.io/atom.xml" rel="self"/>
  
  <link href="http://delia.github.io/"/>
  <updated>2020-10-05T05:18:24.000Z</updated>
  <id>http://delia.github.io/</id>
  
  <author>
    <name>丁大锤</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RPC and Threads</title>
    <link href="http://delia.github.io/2020/10/05/distributed-system-rpc/"/>
    <id>http://delia.github.io/2020/10/05/distributed-system-rpc/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-10-05T05:18:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>多线程协同 垃圾回收<br>1、多线程<br>goroutine</p><a id="more"></a><p>event-driven  和  多线程的区别？<br>当并发量过大时 线程切换的开销较大；一般高性能服务器都是 多线程和事件驱动结合来做</p><p>堆内存和栈内存 分配？<br>lua?</p><p>多线程的挑战：<br>1、共享内存<br>race、 condition 、 临界区问题锁<br>2、coordination<br>channel : 将数据从一个线程发送到另一个线程<br>condition variables ： 确定哪些线程运行<br>wait group:<br>3、死锁</p><p>推荐书籍：<br>1、《effective go》</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;多线程&quot;&gt;&lt;a href=&quot;#多线程&quot; class=&quot;headerlink&quot; title=&quot;多线程&quot;&gt;&lt;/a&gt;多线程&lt;/h2&gt;&lt;p&gt;多线程协同 垃圾回收&lt;br&gt;1、多线程&lt;br&gt;goroutine&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="rpc和线程" scheme="http://delia.github.io/tags/rpc%E5%92%8C%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://delia.github.io/2020/10/05/paging/"/>
    <id>http://delia.github.io/2020/10/05/paging/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-10-05T05:18:24.000Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="Data-Structures-and-Algorithms-for-Big-Database-阅读笔记"><a href="#Data-Structures-and-Algorithms-for-Big-Database-阅读笔记" class="headerlink" title="Data Structures and Algorithms for Big Database 阅读笔记"></a>Data Structures and Algorithms for Big Database 阅读笔记</h2><p>paging algorithms</p><h2 id="IO-and-cache-efficient-algorithm"><a href="#IO-and-cache-efficient-algorithm" class="headerlink" title="IO and cache-efficient algorithm"></a>IO and cache-efficient algorithm</h2><p>Disk Access Model：</p><p>cache-oblivious analysis：</p><h2 id="paging-algorithms"><a href="#paging-algorithms" class="headerlink" title="paging algorithms"></a>paging algorithms</h2><p>page fault,即中不存在所需数据而引入的错误，为了解决这个错误就需要从硬盘中读取数据到内存中。所以每个page fault都对应于一次硬盘读取，耗费大量时间。读到的数据需要覆盖内存中的某些现有数据，如何选择被替代的内存中的数据就是page replacement algorithm处理的问题。</p><p><strong>1.1 LRU: least recently used</strong></p><p>每次选择最不近使用的元素进行替换，算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。<br>首先将请求序列分为b个区块，每个区块内最多有k个元素，并且使得b尽可能小。<br>那么LRU对于每个区块最多遇到k个page fault，从而整体而言最多bk个page fault。而对于最优算法，至少遇到b个page fault，因为每次跳跃区块的时候都会遇到一个前一区块从未遇过的第k+1个元素，从而引入page fault。<br>所以LRU的competitive ratio ≤k，其中k为cache size。</p><p><strong>1.2 FIFO: first in,first out</strong></p><p><strong>1.3 LFU： least frequently used</strong></p><p><strong>1.4 random</strong></p><p><strong>1.5 LFD：longest forward distance</strong></p><p>也叫OPT optimal replacement algorithm<br>淘汰页面将是以后永不使用的，或许是在最长（未来）时间内不再被使用的页面<br>该算法保证了获得最低的缺页率，但是该算法无法实现。但是可以利用该算法去评价其他算法</p><p><strong>1.6  CPR：clock page Replacement Algorithm</strong></p><p>时钟替换算法</p><h2 id="参考blog"><a href="#参考blog" class="headerlink" title="参考blog"></a>参考blog</h2><p><a href="https://blog.csdn.net/silent56_th/article/details/78462738">https://blog.csdn.net/silent56_th/article/details/78462738</a><br><a href="https://www.cnblogs.com/CareySon/archive/2012/04/25/2470063.html">https://www.cnblogs.com/CareySon/archive/2012/04/25/2470063.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;Data-Structures-and-Algorithms-for-Big-Database-阅读笔记&quot;&gt;&lt;a href=&quot;#Data-Structures-and-Algorithms-for-Big-Database-阅读笔记&quot; class=&quot;he</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>GFS</title>
    <link href="http://delia.github.io/2020/10/05/distributed-system-GFS/"/>
    <id>http://delia.github.io/2020/10/05/distributed-system-GFS/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-10-05T05:18:24.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="论文导读"><a href="#论文导读" class="headerlink" title="论文导读"></a>论文导读</h1><p>论文:《The Google File System》<br>关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance </p><a id="more"></a><h2 id="分布式存储面临的问题"><a href="#分布式存储面临的问题" class="headerlink" title="分布式存储面临的问题"></a>分布式存储面临的问题</h2><p>1、component failures<br>持续的监控(monitoring)、错误侦测(error detection)、灾难冗余(fault tolerance,)、 自动恢复(automatic recovery)<br>2、huge files<br>需要考虑IO操作和block设计的大小<br>3、appending new data &amp;&amp; sequentially read （追加写和随机读）<br>因为具有追加写和随机读的特点，可以考虑块缓存设计、数据appending设计<br>4、flexibility<br>通过协同设计来满足灵活性，减轻了GFS一致性的要求； 引进了原子性的追加写</p><h2 id="分布式存储的背景"><a href="#分布式存储的背景" class="headerlink" title="分布式存储的背景"></a>分布式存储的背景</h2><p>1、系统由很多廉价的组件构成，并且组件会经常失败<br>2、系统存储量大，既要支持GB级的大文件，也要支持小文件<br>3、既要支持大规模的流式读取，也要支持小规模的随机读取。 流式读取往往来自同一个客户端，读取一个文件的连续区域； 随机读取某个文件的某个区域，为了提高性能，可以把小规模随机读操作进行合并，变成批量顺序读<br>4、支持大规模顺序追加写，对于小规模的随机写，性能不咋滴<br>5、必须高效的支持多个用户同时写一个文件<br>6、高性能的稳定网络带宽远比低延迟重要</p><h2 id="GFS架构"><a href="#GFS架构" class="headerlink" title="GFS架构"></a>GFS架构</h2><p>什么是GFS: 一个GFS集群是由一个master、多个chunkservers构成，支持多个客服端访问。<br>什么是master节点:<br>什么是chunkserver:<br>什么是chunks：<br>什么是chunk handle: </p><h1 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h1><p>难点：<br>1、性能： SHARDING (分片)<br>2、容错： TOLERANCE -&gt; REPLICATION（副本） -&gt; INCONSISTENCY (副本不一致的问题) -&gt; Low Performance （需要通信来解决副本不一致， 低性能）<br>3、Automatic Recoverry</p><p>3、Bad replication Design</p><p>GFS介绍<br>只处理大文件的顺序访问，而不是随机访问</p><p>MASTER DATA：<br>表1：filename 到 chunk handles的映射  （会写入磁盘）<br>表2： chunk handle 到 chunk server的列表  （不必写入磁盘，master重启后会和server通信）<br>版本、 过期时间、</p><p>读数据：<br>1、文件名+偏移量  发送给master<br>2、master获取handle和servers列表给客户端<br>3、客户端和chunk sever通信，发送文件名和偏移量</p><p>写数据：<br>1、没有primary的情况<br>找出primary和sencondery<br>中心副本控制协议： Primary-secondary协议<br>分布式共识协议 </p><p>2、primary告诉所有的p 和 s 追加写<br>如果所有的s 都回复 “yes”, p 回复 client “success”<br>else p回复client “Fail”, 客户端重新发起追加写</p><p>最小化跨越交换机的处理：client只把数据发到离他最近的副本  然后副本再发送到其它副本  直到所有副本都拿到</p><p>Q：如果master认为priamry挂了怎么办？<br>租约  lease<br>master在指定一个primary的时候会建议一个租约，只在一定时间内，这个chunk是primary，租约到期后，primary就会停止执行master的请求</p><p>Q：SPILT BRAIN(脑裂) : 有两个primary处理请求并且不知道彼此错误的情况，通常是由网络引起的，net partition</p><p>Q：为什么指定一个新的primary是bad?<br>1、client会在短时间内缓存primary的信息<br>2、如果在修改primary的同时，有client的请求过来，会得到两个相互冲突的副本。</p><p>Q：如果有一个文件，但是没有副本 怎么处理？<br>master发现没有chunk和文件关联，就会创建一个新的chunk标识符，再指定一个primary和一些secondaries为这个chunk服务</p><p>Q: 如何将GFS升级成强一致性的系统<br>1、需要检测重复的能力<br>2、sencondary必须能工作，一旦如果磁盘损坏，它需要移除系统<br>3、两阶段提交<br>4、sencondary容易接收到过时的指令，所以可以为sencondary建立一个lease</p><p>GFS最大的问题是 它只用了一个master，需要记录所有的chunk条目，所以主机内存受限。<br>如果主机宕机的话，需要人工介入来切换master</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;论文导读&quot;&gt;&lt;a href=&quot;#论文导读&quot; class=&quot;headerlink&quot; title=&quot;论文导读&quot;&gt;&lt;/a&gt;论文导读&lt;/h1&gt;&lt;p&gt;论文:《The Google File System》&lt;br&gt;关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance &lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="Google文件系统" scheme="http://delia.github.io/tags/Google%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Primary-Backup Replication</title>
    <link href="http://delia.github.io/2020/10/05/distributed-system-primary-backup/"/>
    <id>http://delia.github.io/2020/10/05/distributed-system-primary-backup/</id>
    <published>2020-10-05T05:18:24.000Z</published>
    <updated>2020-10-05T05:18:24.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="论文导读"><a href="#论文导读" class="headerlink" title="论文导读"></a>论文导读</h1><p>论文：《actical System for Practical System forFault-Tolerant Virtual Machines<br>Fault-Tolerant Virtual Machines》</p><a id="more"></a><h1 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h1><p>1、state transfer (状态转移)<br>primary将整个ram都备份， 是转移内存<br>2、replicated state machine (备份状态机) 主<br>转移 operation。相同的状态、相同的启动就会有相同的输出。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;论文导读&quot;&gt;&lt;a href=&quot;#论文导读&quot; class=&quot;headerlink&quot; title=&quot;论文导读&quot;&gt;&lt;/a&gt;论文导读&lt;/h1&gt;&lt;p&gt;论文：《actical System for Practical System forFault-Tolerant Virtual Machines&lt;br&gt;Fault-Tolerant Virtual Machines》&lt;/p&gt;</summary>
    
    
    
    <category term="学习" scheme="http://delia.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="分布式系统" scheme="http://delia.github.io/categories/%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="主从备份" scheme="http://delia.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%87%E4%BB%BD/"/>
    
  </entry>
  
</feed>
