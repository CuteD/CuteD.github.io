<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>airflow部署</title>
    <url>/2020/12/12/airflow%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="搭建airflow"><a href="#搭建airflow" class="headerlink" title="搭建airflow"></a>搭建airflow</h1><p><a href="https://airflow.apache.org/docs/stable/installation.html">官方文档</a></p>
<a id="more"></a>

<h2 id="准备数据库"><a href="#准备数据库" class="headerlink" title="准备数据库"></a>准备数据库</h2><p>CREATE DATABASE airflow_hmc;<br>alter user  XXX with password ‘XXXX’;<br>GRANT ALL PRIVILEGES ON DATABASE airflow TO airflow;  </p>
<h2 id="设置-airflow-项目路径"><a href="#设置-airflow-项目路径" class="headerlink" title="设置 airflow 项目路径"></a>设置 airflow 项目路径</h2><p>vim ~/.bash_profile<br>export AIRFLOW_HOME=/home/xiaoju/airflow</p>
<h2 id="安装airflow"><a href="#安装airflow" class="headerlink" title="安装airflow"></a>安装airflow</h2><p>pip install apache-airflow<br>服务器安装巨慢  可以用公司的源<br>pip install xxx –trusted-host </p>
<h2 id="配置自己的数据库"><a href="#配置自己的数据库" class="headerlink" title="配置自己的数据库"></a>配置自己的数据库</h2><p>更改~/airflow/airflow.cfg<br>executor = LocalExecutor<br>sql_alchemy_conn = postgresql+psycopg2://user:pass@hostadress:port/database<br>最后再重新初始化db</p>
<p>airflow initdb<br>airflow resetdb</p>
<p>然后自动生成数据库结构， 包括job信息、task信息、dag信息。</p>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>airflow webserver -p 8080<br>守护进程启动加 -D</p>
<h2 id="开始demo"><a href="#开始demo" class="headerlink" title="开始demo"></a>开始demo</h2><p><a href="https://blog.csdn.net/SunnyYoona/article/details/76615699">参考</a></p>
<p>编写hello word<br>测试代码正确性: python ~/opt/airflow/dags/hello_world.py<br>展示task任务： airflow list_tasks example_hello_world_dag<br>测试单task正确性 ：airflow test example_hello_world_dag date_task 20170803<br>运行DAG： airflow scheduler就可以在界面上看到自己的任务了</p>
<h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><p>删除默认示例<br>Edit airflow.cfg and set load_examples = False<br>airflow resetdb<br><a href="https://cloud.tencent.com/developer/article/1531063">修改时区</a></p>
<h1 id="搭建分布式"><a href="#搭建分布式" class="headerlink" title="搭建分布式"></a>搭建分布式</h1><h2 id="搭建redis"><a href="#搭建redis" class="headerlink" title="搭建redis"></a>搭建redis</h2><ul>
<li>下载redis包 wget <a href="http://download.redis.io/releases/redis-3.0.7.tar.gz">http://download.redis.io/releases/redis-3.0.7.tar.gz</a> 放在/usr/local/目录下</li>
<li>编译  make   make install PREFIX=/usr/local/redis</li>
<li>启动 /usr/local/redis/bin目录下   ./redis-server &amp;</li>
<li>redis启动 /usr/local/redis/bin$ ./redis-cli -p  6379<h2 id="安装celery"><a href="#安装celery" class="headerlink" title="安装celery"></a>安装celery</h2>pip install celery</li>
</ul>
<h2 id="配置redis"><a href="#配置redis" class="headerlink" title="配置redis"></a>配置redis</h2><p>修改broker_url, result_backend<br>配置主节点位置 cluster_addres</p>
<h2 id="worker-节点部署"><a href="#worker-节点部署" class="headerlink" title="worker 节点部署"></a>worker 节点部署</h2><p>部署了一主两从，在master上启动webserver 和 scheduler<br>在slave上启动 worker</p>
<h2 id="文件同步"><a href="#文件同步" class="headerlink" title="文件同步"></a>文件同步</h2><p>airflow只提供命令同步， 不负责文件同步, 使用rsync进行多节点文件同步</p>
]]></content>
      <categories>
        <category>环境部署</category>
        <category>airflow</category>
      </categories>
      <tags>
        <tag>环境部署</tag>
      </tags>
  </entry>
  <entry>
    <title>airflow简介</title>
    <url>/2020/12/12/airflow%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h1 id="airflow简介"><a href="#airflow简介" class="headerlink" title="airflow简介"></a>airflow简介</h1><p><a href="https://airflow.apache.org/docs/stable/">官方文档</a></p>
<a id="more"></a>

<h2 id="1-1-干嘛的"><a href="#1-1-干嘛的" class="headerlink" title="1.1 干嘛的"></a>1.1 干嘛的</h2><p>分布式任务调度系统</p>
<ul>
<li>组织任务编排</li>
<li>管理任务依赖</li>
<li>调度任务工作流</li>
<li>监视任务执行状态</li>
</ul>
<p><strong>关键字</strong></p>
<ul>
<li>动态性  </li>
<li>可扩展性   可以自动以操作器、执行器等</li>
<li>优雅性  使用jinja模板引擎使 脚本参数化</li>
<li>可伸缩性  模块化 使用消息队列来协调worker</li>
</ul>
<h2 id="1-2-整体架构"><a href="#1-2-整体架构" class="headerlink" title="1.2 整体架构"></a>1.2 整体架构</h2><p><strong>1.2.1 整体介绍</strong><br>在一个可扩展的生产环境中，Airflow通常含有以下组件：</p>
<table>
<thead>
<tr>
<th align="left">组件</th>
<th align="center">名称</th>
<th align="center">职责</th>
<th align="left">职责</th>
</tr>
</thead>
<tbody><tr>
<td align="left">一个元数据库</td>
<td align="center">Database</td>
<td align="center">存储任务、DAGs 变量 连接等信息</td>
<td align="left">MySQL 或 Postgres</td>
</tr>
<tr>
<td align="left">一组Airflow工作节点</td>
<td align="center">Workers</td>
<td align="center">接收任务并执行任务</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">一个Airflow调度器</td>
<td align="center">Scheduler</td>
<td align="center">周期性地轮询任务的调度计划，以确定是否触发任务执行,根据dags生成任务，并提交到消息中间件队列中</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">一个调节器</td>
<td align="center">Celery</td>
<td align="center">队列机制。Celery由Broker（代理）和Result backend（结果后端）两个组件组成。Broker负责存储执行的命令。Result backend存储完成执行命令的状态信息。</td>
<td align="left">Redis或RabbitMQ</td>
</tr>
<tr>
<td align="left">一个Airflow Web服务器</td>
<td align="center">WebServer</td>
<td align="center">提供web端服务，以及会定时生成子进程去扫描对应的目录下的dags，并更新数据库</td>
<td align="left"></td>
</tr>
</tbody></table>
<p><img src="https://airflow.apache.org/docs/apache-airflow/stable/_images/graphviz-91fd3ca4f3dc01a69b3f84fbcd6b5c7975945ba4.png" alt="架构图" title="架构图"></p>
<p>各种组件之间的通信</p>
<ol>
<li>Web server –&gt; Workers ： 获取任务执行日志。</li>
<li>Web server –&gt; DAG files ： 展示DAG结构。</li>
<li>Web server –&gt; Database ：获取任务状态。</li>
<li>Workers –&gt; DAG files ：展示DAG结构和执行任务。</li>
<li>Workers –&gt; Database ： 获取和存储连接配置信息、变量XCOM。</li>
<li>Workers –&gt; Celery’s result backend ： 存储任务执行信息。</li>
<li>Workers –&gt; Celery’s broker ：存储执行的命令。</li>
<li>Scheduler –&gt; Database ： 存储DAG运行信息和相关的任务。</li>
<li>Scheduler –&gt; DAG files ： 展示DAG的结构和执行任务。</li>
<li>Scheduler –&gt; Celery’s result backend ： 获取已经执行完的任务信息。</li>
<li>Scheduler –&gt; Celery’s broker ： 把执行的命令发送给Celery’s broker。</li>
</ol>
<p><strong>1.2.2  单机模式和分布式模式的区别</strong><br>Worker的具体实现由配置文件中的executor来指定，airflow支持多种Executor:</p>
<ul>
<li>SequentialExecutor: 单进程顺序执行，一般只用来测试</li>
<li>LocalExecutor: 本地多进程执行</li>
<li>CeleryExecutor: 使用Celery进行分布式任务调度</li>
<li>DaskExecutor：使用Dask进行分布式任务调度</li>
<li>KubernetesExecutor: 1.10.0新增, 创建临时POD执行每次任务<br>其中常用的是CeleryExecutor 和 KubernetesExecutor。 这里介绍下LocalExecutor 和 CeleryExecutor 分别代表单机和分布式模式。</li>
</ul>
<p>分布式模式<br><img src="https://img-blog.csdnimg.cn/20190916182738947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTY1ODQzNA==,size_16,color_FFFFFF,t_70" alt="单机模式"></p>
<ol>
<li>Schedual读取配置文件 将Job信息发给RabbitMQ， 并在数据库里注册Job信息</li>
<li>RabbitMQ里有很多channel， schedual根据Job信息 发到对应的channel</li>
<li>Executor会被配置为 Celery Executor（在 airflow.cfg 中配置），并且指向 RabbitMQ Broker， 消费RabbitMQ对应的channel。  </li>
<li>Worker 被安装在不同的节点上，它们从 RabbitMQ Broker 中读取任务，并执行，最终将结果写入数据库。</li>
<li>Web读取MySQL里面的Job信息，展示Job的执行结果</li>
</ol>
<p>单机模式<br><img src="https://img-blog.csdnimg.cn/2019091618314065.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTY1ODQzNA==,size_16,color_FFFFFF,t_70" alt="单机模式"></p>
<h2 id="1-3-核心概念"><a href="#1-3-核心概念" class="headerlink" title="1.3  核心概念"></a>1.3  核心概念</h2><p><strong>1.3.1 DAG图</strong> </p>
<p>即有向无环图(Directed Acyclic Graph)，将所有需要运行的tasks按照依赖关系组织起来, 描述的是一个工作流的过程。<br>DAG 不关心里面的任务做了什么事情，而是关心  </p>
<ul>
<li>任务在特定的时间开始</li>
<li>若干任务以正确的顺序进行</li>
<li>对未期望的情况有正确的处理</li>
</ul>
<p><strong>1.3.2 Operators</strong><br>DAG定义了一个工作流，operators定义了工作流中的每一task具体做什么事情。一个operator定义工作流中一个task，每个operator是独立执行的，不需要和其他的operator共享信息。它们可以分别在不同的机器上执行。<br>如果你真的需要在两个operator之间共享信息，可以使用airflow提供的Xcom功能。  </p>
<p><strong>1.3.3 Tasks</strong><br>Task为DAG中具体的作业任务，依赖于DAG，也就是必须存在于某个DAG中。<br>Task在DAG中可以配置依赖关系（当然也可以配置跨DAG依赖，但是并不推荐。跨DAG依赖会导致DAG图的直观性降低，并给依赖管理带来麻烦）。</p>
<p><strong>1.3.4 Hooks</strong><br>建立一个与外部数据系统之间的连接，比如Mysql，HDFS，本地文件系统(文件系统也被认为是外部系统)等，通过拓展Hook能够接入任意的外部系统的接口进行连接，这样就解决的外部系统依赖问题。  </p>
<p>##1.3  优缺点<br><strong>优点</strong>  </p>
<ol>
<li>解决任务依赖问题，可以设定各种触发条件, 便于对任务进行状态管理</li>
<li>丰富的ui管理界面，任务的启停、日志管理、甘特图等 可以便捷的知道程序运行状态。  </li>
</ol>
<p><strong>缺点</strong>  </p>
<ol>
<li>分布式部署麻烦</li>
<li>task拆分得很细，这样的话，如果某个task失败，重跑的代价会比较低。但是，tasks太多时，airflow在调度tasks会很低效，airflow一直处于选择待执行的task的过程中，会长时间没有具体task在执行，从而整体执行效率大幅降低。  </li>
</ol>
<h2 id="1-4-竞品比较"><a href="#1-4-竞品比较" class="headerlink" title="1.4 竞品比较"></a>1.4 竞品比较</h2><p>Apache Airflow<br>LinkedIn Azkaban<br>Apache Oozie</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>分布式调度</category>
      </categories>
      <tags>
        <tag>分布式调度</tag>
      </tags>
  </entry>
  <entry>
    <title>GFS</title>
    <url>/2020/10/05/distributed-system-GFS/</url>
    <content><![CDATA[<h1 id="论文导读"><a href="#论文导读" class="headerlink" title="论文导读"></a>论文导读</h1><p>论文:《The Google File System》<br>关键词：1、data-intensive  2、fault tolerance  3、high aggregate performance </p>
<a id="more"></a>

<h2 id="分布式存储的背景"><a href="#分布式存储的背景" class="headerlink" title="分布式存储的背景"></a>分布式存储的背景</h2><ol>
<li>系统由很多廉价的组件构成，并且组件会经常失败， 因此要注意持续的监控 、错误侦测、灾难冗余、 自动恢复</li>
<li>系统存储量大，支持GB级的大文件，因此需要考虑IO操作和block设计的大小</li>
<li>既要支持大规模的流式读取，也要支持小规模的随机读取。 为了提高性能，可以把小规模随机读操作进行合并，变成批量顺序读</li>
<li>支持大规模顺序追加写，对于小规模的随机写，性能不咋滴</li>
<li>必须高效的支持多个用户同时写一个文件，通过协同设计来满足灵活性，减轻了GFS一致性的要求； 引进了原子性的追加写</li>
<li>高性能的稳定网络带宽远比低延迟重要</li>
</ol>
<h2 id="GFS架构"><a href="#GFS架构" class="headerlink" title="GFS架构"></a>GFS架构</h2><p>GFS: 一个GFS集群是由一个master、多个chunkservers构成，支持多个客服端访问。</p>
<h3 id="master"><a href="#master" class="headerlink" title="master"></a>master</h3><p>因为master节点只有一个，所以要减少它的读写，避免master成为瓶颈。因此客户端和Master节点的通信只获取元数据，所有的数据操作都是由客户端直接和Chunk服务器进行交互的<br>读流程：</p>
<ul>
<li>Step1 客户端根据文件名和字节偏移生成chunk index</li>
<li>Step2 客户端把chunk index 和 文件名 发送给master</li>
<li>Step3 master返回对应的chunk handle 和 副本的位置</li>
<li>Step4 客户端会以文件名和chunk index 来缓存信息 (chunk handle 和 副本)</li>
<li>Step5 客户端会向最近的一个副本请求数据</li>
</ul>
<p>写流程：</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="chunk-server"><a href="#chunk-server" class="headerlink" title="chunk server"></a>chunk server</h3><p>chunk size的大小直接影响系统的吞吐指标，chunk size越大越能利用磁盘的顺序读能力<br>一个chunk一般选用64MB（一般文件系统的块大小是4K），采用惰性空间分配防止内存碎片造成空间浪费？？？<br>优点：</p>
<ol>
<li>减少客服端和主节点的直接交互</li>
<li>通过tcp长连接来减少网络IO</li>
<li>减少了存储在主节点上的元数据</li>
</ol>
<p>缺点：</p>
<ol>
<li>当大量客户端访问相同文件，容易产生热点问题。但由于缓存和顺序读，不会是大问题</li>
<li>批处理队列系统里，还是会出现热点问题( 没看懂)，短期解决办法:多复制几份、错开程序的启动时间，长期解决办法：允许从其它客服端读取</li>
</ol>
<h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><p>master服务器存储3种类型的元数据：</p>
<ol>
<li>文件和块的命名空间, master内存 &amp;&amp; master磁盘 &amp;&amp; chunk 副本</li>
<li>文件到块的映射关系,  master内存 &amp;&amp;  master磁盘 &amp;&amp; chunk 副本</li>
<li>块副本的存储位置, master内存</li>
</ol>
<p>一、内存数据结构<br>master会定期扫描，用来实现chunk的垃圾回收、chunkserver失败时候的副本复制、以及平衡负载的chunk迁移？<br>一个问题是系统受限于master的内存，但不严重因为一个chunk的meta不足64kb，文件名也是以压缩的方式存储</p>
<p>二、chunk位置<br>为了解决master和chunkserver的同步问题，块位置缓存在内存不落盘，master启动时通过请求chunkserver获取位置信息，通过心跳来监控chunkserver的状态。</p>
<p>三、操作日志<br>为了确保操作日志的完整性，只有日志写到本地以及远程磁盘后，才会响应客户端操作。<br>1、master在操作日志量级达到一定程度时，会创建一个checkpoint文件，写入本地和远程的硬盘；<br>2、为了保证checkpoint文件不阻塞服务，会用独立线程切换到新的线程和checkpoint文件<br>3、master进行灾难恢复的时候，只需要恢复checkpoint和后面的日志文件。历史可以删除</p>
<h3 id="Consistency-Model"><a href="#Consistency-Model" class="headerlink" title="Consistency Model"></a>Consistency Model</h3><p>一、一致性保障机制<br>命名空间锁保证了原子性和正确性，操作日志保证了保证了顺序。<br>a) 对Chunk的所有副本的修改操作顺序一致<br>b) 通过chunk版本号来去掉过时的chunk<br>GFS通过master和chunkservers的定期handshake来检测破坏了的数据</p>
<p>二、应用实现<br>GFS采用几个简单的技术来保证它的一致性： 追加写、checkpoint、自验证、自识别？？<br>当很多用户同时追加写到一个文件的时候：每条写入的记录可以通过checksum来验证有效性</p>
<h2 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h2><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h1 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h1><p>难点：<br>1、性能： SHARDING (分片)<br>2、容错： TOLERANCE -&gt; REPLICATION（副本） -&gt; INCONSISTENCY (副本不一致的问题) -&gt; Low Performance （需要通信来解决副本不一致， 低性能）<br>3、Automatic Recoverry</p>
<p>3、Bad replication Design</p>
<p>GFS介绍<br>只处理大文件的顺序访问，而不是随机访问</p>
<p>MASTER DATA：<br>表1：filename 到 chunk handles的映射  （会写入磁盘）<br>表2： chunk handle 到 chunk server的列表  （不必写入磁盘，master重启后会和server通信）<br>版本、 过期时间、</p>
<p>读数据：<br>1、文件名+偏移量  发送给master<br>2、master获取handle和servers列表给客户端<br>3、客户端和chunk sever通信，发送文件名和偏移量</p>
<p>写数据：<br>1、没有primary的情况<br>找出primary和sencondery<br>中心副本控制协议： Primary-secondary协议<br>分布式共识协议 </p>
<p>2、primary告诉所有的p 和 s 追加写<br>如果所有的s 都回复 “yes”, p 回复 client “success”<br>else p回复client “Fail”, 客户端重新发起追加写</p>
<p>最小化跨越交换机的处理：client只把数据发到离他最近的副本  然后副本再发送到其它副本  直到所有副本都拿到</p>
<p>Q：如果master认为priamry挂了怎么办？<br>租约  lease<br>master在指定一个primary的时候会建议一个租约，只在一定时间内，这个chunk是primary，租约到期后，primary就会停止执行master的请求</p>
<p>Q：SPILT BRAIN(脑裂) : 有两个primary处理请求并且不知道彼此错误的情况，通常是由网络引起的，net partition</p>
<p>Q：为什么指定一个新的primary是bad?<br>1、client会在短时间内缓存primary的信息<br>2、如果在修改primary的同时，有client的请求过来，会得到两个相互冲突的副本。</p>
<p>Q：如果有一个文件，但是没有副本 怎么处理？<br>master发现没有chunk和文件关联，就会创建一个新的chunk标识符，再指定一个primary和一些secondaries为这个chunk服务</p>
<p>Q: 如何将GFS升级成强一致性的系统<br>1、需要检测重复的能力<br>2、sencondary必须能工作，一旦如果磁盘损坏，它需要移除系统<br>3、两阶段提交<br>4、sencondary容易接收到过时的指令，所以可以为sencondary建立一个lease</p>
<p>GFS最大的问题是 它只用了一个master，需要记录所有的chunk条目，所以主机内存受限。<br>如果主机宕机的话，需要人工介入来切换master</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Google文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Primary-Backup Replication</title>
    <url>/2020/10/05/distributed-system-primary-backup/</url>
    <content><![CDATA[<h1 id="论文导读"><a href="#论文导读" class="headerlink" title="论文导读"></a>论文导读</h1><p>论文：《actical System for Practical System forFault-Tolerant Virtual Machines<br>Fault-Tolerant Virtual Machines》</p>
<a id="more"></a>


<h1 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h1><p>1、state transfer (状态转移)<br>primary将整个ram都备份， 是转移内存<br>2、replicated state machine (备份状态机) 主<br>转移 operation。相同的状态、相同的启动就会有相同的输出。</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>主从备份</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC and Threads</title>
    <url>/2020/10/05/distributed-system-rpc/</url>
    <content><![CDATA[<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>多线程协同 垃圾回收<br>1、多线程<br>goroutine</p>
<a id="more"></a>

<p>event-driven  和  多线程的区别？<br>当并发量过大时 线程切换的开销较大；一般高性能服务器都是 多线程和事件驱动结合来做</p>
<p>堆内存和栈内存 分配？<br>lua?</p>
<p>多线程的挑战：<br>1、共享内存<br>race、 condition 、 临界区问题锁<br>2、coordination<br>channel : 将数据从一个线程发送到另一个线程<br>condition variables ： 确定哪些线程运行<br>wait group:<br>3、死锁</p>
<p>推荐书籍：<br>1、《effective go》</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>rpc和线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Data Structures and Algorithms for Big Database 阅读笔记</title>
    <url>/2020/10/05/paging/</url>
    <content><![CDATA[<h2 id="IO-and-cache-efficient-algorithm"><a href="#IO-and-cache-efficient-algorithm" class="headerlink" title="IO and cache-efficient algorithm"></a>IO and cache-efficient algorithm</h2><p>Disk Access Model：</p>
<p>cache-oblivious analysis：</p>
<a id="more"></a>

<h2 id="paging-algorithms"><a href="#paging-algorithms" class="headerlink" title="paging algorithms"></a>paging algorithms</h2><p>page fault,即中不存在所需数据而引入的错误，为了解决这个错误就需要从硬盘中读取数据到内存中。所以每个page fault都对应于一次硬盘读取，耗费大量时间。读到的数据需要覆盖内存中的某些现有数据，如何选择被替代的内存中的数据就是page replacement algorithm处理的问题。</p>
<p><strong>1.1 LRU: least recently used</strong></p>
<p>每次选择最不近使用的元素进行替换，算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。<br>首先将请求序列分为b个区块，每个区块内最多有k个元素，并且使得b尽可能小。<br>那么LRU对于每个区块最多遇到k个page fault，从而整体而言最多bk个page fault。而对于最优算法，至少遇到b个page fault，因为每次跳跃区块的时候都会遇到一个前一区块从未遇过的第k+1个元素，从而引入page fault。<br>所以LRU的competitive ratio ≤k，其中k为cache size。</p>
<p><strong>1.2 FIFO: first in,first out</strong></p>
<p><strong>1.3 LFU： least frequently used</strong></p>
<p><strong>1.4 random</strong></p>
<p><strong>1.5 LFD：longest forward distance</strong></p>
<p>也叫OPT optimal replacement algorithm<br>淘汰页面将是以后永不使用的，或许是在最长（未来）时间内不再被使用的页面<br>该算法保证了获得最低的缺页率，但是该算法无法实现。但是可以利用该算法去评价其他算法</p>
<p><strong>1.6  CPR：clock page Replacement Algorithm</strong></p>
<p>时钟替换算法</p>
<h2 id="参考blog"><a href="#参考blog" class="headerlink" title="参考blog"></a>参考blog</h2><p><a href="https://blog.csdn.net/silent56_th/article/details/78462738">https://blog.csdn.net/silent56_th/article/details/78462738</a><br><a href="https://www.cnblogs.com/CareySon/archive/2012/04/25/2470063.html">https://www.cnblogs.com/CareySon/archive/2012/04/25/2470063.html</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>LevelDB</category>
      </categories>
      <tags>
        <tag>paging algorithms</tag>
      </tags>
  </entry>
</search>
